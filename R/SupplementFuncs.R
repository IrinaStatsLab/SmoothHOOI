# Create the second order difference matrix with a circular nature
# dim - dimension of the second order difference matrix 
SecDiffMat <- function(dim){
  D2 <- diag(2,dim,dim)
  D2[row(D2) == col(D2) - 1] <- -1
  D2[row(D2) == col(D2) + 1] <- -1
  D2[dim,1] <- -1
  D2[1,dim] <- -1
  return(D2)
}

# mask a certain percent of data randomly across the tensor
# tnsr - tnsr to be masked
# percent - percent of data to be masked
mask1<-function(tnsr,percent){
  idx <- which(!is.na(tnsr@data))
  rand_sample <- sample(length(idx),ceiling(length(idx)*percent))
  masked_idx <- idx[rand_sample]
  masked_tnsr <- tnsr@data
  masked_tnsr[masked_idx] <- NA
  masked_tnsr <- rTensor::as.tensor(masked_tnsr)
  return(masked_tnsr)
}

# mask a certain percent of data for each slice (usually each individual) evenly
# tnsr - tnsr to be masked
# modes - the minimum unit you want to create missing values in
# percent - percent of data to be masked
mask2<-function(tnsr, modes, percent){ 
  unfolded <- rTensor::unfold(tnsr, row_idx=modes, col_idx = setdiff(seq(1,tnsr@num_modes,by=1),modes))
  n <- dim(unfolded)[1]
  m <- dim(unfolded)[2]
  for (i in 1:m){
    idx <- which(!is.na(unfolded@data[,i]))
    rand_sample <- sample(length(idx),ceiling(length(idx)*percent))
    unfolded[rand_sample,i] <- NA 
  }
  masked_tnsr <- rTensor::fold(unfolded, row_idx = modes, col_idx = setdiff(seq(1,tnsr@num_modes,by=1),modes), modes = tnsr@modes)
  return(masked_tnsr)
}

# mask a random percent of data for different slices of the tensor (usually individuals)
# tnsr - tnsr to be masked
# modes - the minimum unit you want to create missing values in
# percent - percent of data to be masked
mask3<-function(tnsr, modes){ 
  unfolded <- rTensor::unfold(tnsr, row_idx=modes, col_idx = setdiff(seq(1,tnsr@num_modes,by=1),modes))
  n <- dim(unfolded)[1]
  m <- dim(unfolded)[2]
  percent <- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)
  for (i in 1:m){
    idx <- which(!is.na(unfolded@data[,i]))
    percent_i <- sample(percent,1)
    rand_sample <- sample(length(idx),ceiling(length(idx)*percent_i))
    unfolded[rand_sample,i] <- NA 
  }
  masked_tnsr <- rTensor::fold(unfolded, row_idx = modes, col_idx = setdiff(seq(1,tnsr@num_modes,by=1),modes), modes = tnsr@modes)
  return(masked_tnsr)
}

# This function is to mask the ABPM data in a structured way: 0-20 timepoints in a 24-hour period
# tnsr - tnsr to be masked 
mask4 <- function(tnsr){
  n <- tnsr@modes[3]
  for (i in 1:n){
    mask_num <- sample(c(0:20), 1)
    mask_tp <- sample(c(1:24), mask_num)
    tnsr@data[mask_tp, ,i] <- NA
  }
  return(tnsr)
}

# Generate simulated data, when the following information are available
# return the smooth, complete underlying data and the noisy, incomplete data
# L, G, R: results generated by cglram/mglram on a real data
# E: residuals between the real data and LGR^T
# p: number of samples (e.g. patients in ABPM data)
# noise_level: >=0
# pattern: "random" or "structured"
# percent: percent of data to be masked, if pattern = "random"
simdata_generator <- function(L, G, R, E, p, noise_level, pattern, percent){
  G_mat <- cbind(G[1,1,], G[1,2,], 
                 G[2,1,], G[2,2,],
                 G[3,1,], G[3,2,])
  
  mean_G <- colMeans(G_mat)
  cov_G <- cov(G_mat)
  
  error_sd <- sd(E, na.rm=T)
  
  # simulate core tensor G
  sim_G <- array(NA, dim=c(3, 2, p))
  for (i in 1:p){
    sim <- MASS::mvrnorm(n = 1, mu = mean_G, Sigma = cov_G)
    sim_G[,,i] <- matrix(sim, nrow=3, byrow=TRUE)
  }
  
  # make a smooth, complete data 
  sim_Msmooth <- rTensor::ttl(rTensor::as.tensor(sim_G), list_mat=list(L, R), ms=c(1,2))
  
  # add error (noise) to the smooth, complete data 
  error_array <- array(rnorm(24*3*p, mean=0, sd=error_sd*noise_level), dim=c(24,3,p))
  sim_Mnoise <- rTensor::as.tensor(sim_Msmooth@data + error_array)
  
  # mask the noisy data
  if (pattern=="random"){
    sim_Mmiss <- mask1(sim_Mnoise, percent = percent)
  } else if (pattern=="structured"){
    sim_Mmiss <- mask4(sim_Mnoise)
  }
  
  out=list(sim_Msmooth=sim_Msmooth, sim_Mmiss=sim_Mmiss)
}

# Run FPCA and return the losses 
# tnsr: simulated noisy, incomplete data
# smooth_tnsr: underlying smooth, complete data 
# true L: ground truth of L
# npc, pve, center: arguments required in refund::fpca()
fpca_res <- function(tnsr, smooth_tnsr, true_L, npc=NULL, pve=0.99, center=TRUE){
  nmiss_idx <- which(!is.na(tnsr@data))
  b <- tnsr@modes[2]
  
  h <- list()
  outfpca <- list()
  for (i in 1:b){
    h[[i]] <- rTensor::unfold(tnsr[,i,], row_idx = 2, col_idx = 1)@data
    outfpca[[i]] <- refund::fpca.sc(Y = as.matrix(h[[i]]), pve=pve, npc = npc, center=center)
  }
  
  # h1 <- rTensor::unfold(tnsr[,1,], row_idx = 2, col_idx = 1)@data
  # h2 <- rTensor::unfold(tnsr[,2,], row_idx = 2, col_idx = 1)@data
  # h3 <- rTensor::unfold(tnsr[,3,], row_idx = 2, col_idx = 1)@data
  
  # outfpca1 <- refund::fpca.sc(Y = as.matrix(h1), pve=pve, npc = npc, center=center)
  # outfpca2 <- refund::fpca.sc(Y = as.matrix(h2), pve=pve, npc = npc, center=center)
  # outfpca3<- refund::fpca.sc(Y = as.matrix(h3), pve=pve, npc = npc, center=center)
  
  p <- tnsr@modes[3]
  outfpcaYhat <- array(NA, dim=tnsr@modes)
  
  for (i in 1:p){
    for (j in 1:b){
      outfpcaYhat[,j,i] <- outfpca[[j]]$Yhat[i,] # yhat is the estimated, smoothed curve, with missing data imputed
    }
  }
  
  # for (i in 1:p){
  #   outfpcaYhat[,1,i] <- outfpca1$Yhat[i,]
  #   outfpcaYhat[,2,i] <- outfpca2$Yhat[i,]
  #   outfpcaYhat[,3,i] <- outfpca3$Yhat[i,]
  # }
  
  # Calculate loss of M
  loss_M <- sum((outfpcaYhat - smooth_tnsr@data)^2)/length(outfpcaYhat)
  
  # take the minimum number of columns among the estimated L matrices
  min_col <- min(sapply(outfpca[1:b], function(x) ncol(x$efunctions)))
  # min_col <- min(ncol(outfpca1$efunctions), ncol(outfpca2$efunctions), ncol(outfpca3$efunctions))
  
  # Take average of the estimated L matrice and ensure orthogonality using qr decomposition
  Lfpca <- list()
  for (i in 1:b){
    Lfpca_i <- outfpca[[i]]$efunctions[,1:min_col]
    Lfpca[[i]] <- qr.Q(qr(Lfpca_i))
  }
  
  Lfpca_avg <- Reduce("+", Lfpca) / length(Lfpca)
  Lfpca_avg <- qr.Q(qr(Lfpca_avg))
  
  # Lfpca1 <- outfpca1$efunctions[,1:min_col]
  # Lfpca2 <- outfpca2$efunctions[,1:min_col]
  # Lfpca3 <- outfpca3$efunctions[,1:min_col]
  
  # Lfpca1 <- qr.Q(qr(Lfpca1))
  # Lfpca2 <- qr.Q(qr(Lfpca2))
  # Lfpca3 <- qr.Q(qr(Lfpca3))
  # 
  # Lfpca <- (Lfpca1 + Lfpca2 + Lfpca3)/3
  # Lfpca <- qr.Q(qr(Lfpca))
  
  loss_L <- sqrt(0.5*sum((true_L %*% t(true_L) - Lfpca_avg %*% t(Lfpca_avg))^2))
  
  out=list(est=outfpcaYhat, Lfpca=Lfpca_avg, loss_M=loss_M, loss_L=loss_L)
}


# Rotation to guarantee identifiability for downstream inference
# L - L generated by cglram/mglram
# G - G generated by cglram/mglram
# R - R generated by cglram/mglram
MakeIdent <- function(L, G, R){
  unfold1 <- rTensor::k_unfold(rTensor::as.tensor(G), m = 1) # Unfold by mode 1
  svdmode1 <- svd(unfold1@data)
  U_1 = svdmode1$u
  
  unfold2 <- rTensor::k_unfold(rTensor::as.tensor(G), m = 2) # Unfold by mode 2
  svdmode2 <- svd(unfold2@data)
  U_2 = svdmode2$u
  
  n = dim(G)[3] 
  G_tilde <- array(NA, dim = dim(G))
  for (i in 1:n){
    G_tilde[, , i] = t(U_1) %*% G[, , i] %*% U_2 
  }
  
  L_tilde = L %*% U_1 
  R_tilde = R %*% U_2
  
  out = list(L_tilde = L_tilde, R_tilde = R_tilde, G_tilde = G_tilde)
}


